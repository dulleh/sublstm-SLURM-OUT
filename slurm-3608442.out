Running on host gpu32.bc4.acrc.priv
Slurm job ID is 3608442
This job runs on the following machines:
gpu32
Obtaining file:///mnt/storage/home/mk17486/neural-networks/pytorch-subLSTM
Requirement already satisfied: numpy in /mnt/storage/home/mk17486/.local/lib/python3.7/site-packages (from torch-sublstm==0.1.0) (1.18.1)
Requirement already satisfied: torch in /mnt/storage/home/mk17486/.local/lib/python3.7/site-packages (from torch-sublstm==0.1.0) (1.4.0)
Installing collected packages: torch-sublstm
  Found existing installation: torch-sublstm 0.1.0
    Uninstalling torch-sublstm-0.1.0:
      Successfully uninstalled torch-sublstm-0.1.0
  Running setup.py develop for torch-sublstm
Successfully installed torch-sublstm
subLSTMCuda
def forward(self,
    input: Tensor,
    state: Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tensor]:
  old_h, old_cell, = state
  _0 = [torch.detach(old_h), torch.detach(input)]
  X = torch.cat(_0, 1)
  X0 = torch.detach(X)
  _1 = torch.detach(self.bias)
  _2 = torch.transpose(torch.detach(self.weights), 0, 1)
  gate_weights = torch.addmm(_1, X0, _2, beta=1, alpha=1)
  _3 = ops.sublstm.apply(input, self.weights, self.bias, old_h, old_cell, [X0, gate_weights])
  new_h, new_cell, = _3
  return (new_h, new_cell)

def forward(self,
    input: Tensor,
    state: Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tensor]:
  old_h, old_cell, = state
  _0 = [torch.detach(old_h), torch.detach(input)]
  X = torch.cat(_0, 1)
  X0 = torch.detach(X)
  _1 = torch.detach(self.bias)
  _2 = torch.transpose(torch.detach(self.weights), 0, 1)
  gate_weights = torch.addmm(_1, X0, _2, beta=1, alpha=1)
  _3 = ops.sublstm.apply(input, self.weights, self.bias, old_h, old_cell, [X0, gate_weights])
  new_h, new_cell, = _3
  return (new_h, new_cell)

-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 64.85s | valid loss  5.71 | valid ppl   300.38
-----------------------------------------------------------------------------------------
Cannot yet save a CUDA model.Must make subLSTM be entirely traced
Traceback (most recent call last):
  File "main.py", line 257, in <module>
    model = torch.load(f)
  File "/mnt/storage/home/mk17486/.local/lib/python3.7/site-packages/torch/serialization.py", line 526, in load
    if _is_zipfile(opened_file):
  File "/mnt/storage/home/mk17486/.local/lib/python3.7/site-packages/torch/serialization.py", line 76, in _is_zipfile
    if ord(magic_byte) != ord(read_byte):
TypeError: ord() expected a character, but string of length 0 found
