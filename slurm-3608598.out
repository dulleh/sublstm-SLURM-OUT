Running on host gpu32.bc4.acrc.priv
Slurm job ID is 3608598
This job runs on the following machines:
gpu32
Obtaining file:///mnt/storage/home/mk17486/neural-networks/pytorch-subLSTM
Requirement already satisfied: numpy in /mnt/storage/home/mk17486/.local/lib/python3.7/site-packages (from torch-sublstm==0.1.0) (1.18.1)
Requirement already satisfied: torch in /mnt/storage/home/mk17486/.local/lib/python3.7/site-packages (from torch-sublstm==0.1.0) (1.4.0)
Installing collected packages: torch-sublstm
  Found existing installation: torch-sublstm 0.1.0
    Uninstalling torch-sublstm-0.1.0:
      Successfully uninstalled torch-sublstm-0.1.0
  Running setup.py develop for torch-sublstm
Successfully installed torch-sublstm
subLSTMCuda
def forward(self,
    input: Tensor,
    state: Optional[List[Tuple[Tensor, Tensor]]]) -> Tuple[Tensor, List[Tuple[Tensor, Tensor]]]:
  if self.batch_first:
    max_batch_size = torch.size(input, 0)
  else:
    max_batch_size = torch.size(input, 1)
  hx = annotate(List[Tuple[Tensor, Tensor]], [])
  if torch.__is__(state, None):
    for l in range(self.num_layers):
      _0 = [max_batch_size, self.hidden_size]
      _1 = torch.new_zeros(input, _0, dtype=None, layout=None, device=None, pin_memory=None)
      hidden = torch.detach(_1)
      _2 = torch.append(hx, (hidden, hidden))
    hx0 = hx
  else:
    hx0 = unchecked_cast(List[Tuple[Tensor, Tensor]], state)
  if self.batch_first:
    input0 = torch.contiguous(torch.transpose(input, 0, 1), memory_format=0)
  else:
    input0 = input
  timesteps = torch.size(input0, 0)
  outputs = []
  for i in range(timesteps):
    _3 = torch.append(outputs, torch.select(input0, 0, i))
  for time in range(timesteps):
    _4 = self.all_layers
    _5 = getattr(_4, "0")
    _6 = getattr(_4, "1")
    _7 = (self).flatten_parameters()
    _8 = (_5).forward(outputs[time], hx0[0], )
    out, c, = _8
    if self.use_dropout:
      out0 = (self.dropout).forward(out, )
    else:
      out0 = out
    _9 = torch._set_item(hx0, 0, (out0, c))
    _10 = torch._set_item(outputs, time, out0)
    _11 = (self).flatten_parameters()
    _12 = (_6).forward(outputs[time], hx0[1], )
    out1, c0, = _12
    if self.use_dropout:
      out2 = (self.dropout).forward(out1, )
    else:
      out2 = out1
    _13 = torch._set_item(hx0, 1, (out2, c0))
    _14 = torch._set_item(outputs, time, out2)
  out3 = torch.stack(outputs, 0)
  if self.batch_first:
    out4 = torch.transpose(out3, 0, 1)
  else:
    out4 = out3
  return (out4, hx0)

Traceback (most recent call last):
  File "main.py", line 102, in <module>
    model = torch.jit.script(model)
  File "/mnt/storage/home/mk17486/.local/lib/python3.7/site-packages/torch/jit/__init__.py", line 1255, in script
    return torch.jit._recursive.recursive_script(obj)
  File "/mnt/storage/home/mk17486/.local/lib/python3.7/site-packages/torch/jit/_recursive.py", line 534, in recursive_script
    return create_script_module(nn_module, infer_methods_to_compile(nn_module))
  File "/mnt/storage/home/mk17486/.local/lib/python3.7/site-packages/torch/jit/_recursive.py", line 296, in create_script_module
    return create_script_module_impl(nn_module, concrete_type, cpp_module, stubs)
  File "/mnt/storage/home/mk17486/.local/lib/python3.7/site-packages/torch/jit/_recursive.py", line 340, in create_script_module_impl
    create_methods_from_stubs(concrete_type, stubs)
  File "/mnt/storage/home/mk17486/.local/lib/python3.7/site-packages/torch/jit/_recursive.py", line 259, in create_methods_from_stubs
    concrete_type._create_methods(defs, rcbs, defaults)
RuntimeError: 

forward(__torch__.subLSTM.basic.nn.SubLSTM self, Tensor input, (Tensor, Tensor)[]? state) -> ((Tensor, (Tensor, Tensor)[])):
Expected a value of type 'Optional[List[Tuple[Tensor, Tensor]]]' for argument 'state' but instead found type 'Tensor'.
:
  File "/mnt/storage/home/mk17486/neural-networks/pytorch-subLSTM/tasks/word_language_model/model.py", line 76
    def forward(self, input, hidden):
        emb = self.drop(self.encoder(input))
        output, hidden = self.rnn(emb, hidden)
                         ~~~~~~~~ <--- HERE
        output = self.drop(output)
        decoded = self.decoder(output.reshape(output.size(0)*output.size(1), output.size(2)))

